<html>
<head>
<title>Deploying Spark on Kubernetes </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>在Kubernetes上部署Spark</h1>
<blockquote>原文：<a href="https://testdriven.io/blog/deploying-spark-on-kubernetes/#0001-01-01">https://testdriven.io/blog/deploying-spark-on-kubernetes/#0001-01-01</a></blockquote><div><div class="blog-content long-content" data-local-nav-source="">
    <p>这篇文章详细介绍了如何在Kubernetes集群上部署Spark。</p>
<p><em>依赖关系:</em></p>
<ul>
<li>文档版本20.10.10</li>
<li>Minikube v1.24.0</li>
<li>spark 3 . 2 . 0版</li>
<li>Hadoop版本3.3.1</li>
</ul>



<h2 id="minikube">迷你库贝</h2>
<p>Minikube是一个用于在本地运行单节点Kubernetes集群的工具。</p>
<p>遵循官方的<a href="https://kubernetes.io/docs/tasks/tools/install-minikube/">安装Minikube </a>指南，将其与<a href="https://kubernetes.io/docs/tasks/tools/install-minikube/#install-a-hypervisor">虚拟机管理程序</a>(如<a href="https://www.virtualbox.org/wiki/Downloads"> VirtualBox </a>或<a href="https://github.com/moby/hyperkit"> HyperKit </a>)一起安装，以管理虚拟机，并与<a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/"> Kubectl </a>一起安装，以在Kubernetes上部署和管理应用。</p>
<p>默认情况下，Minikube虚拟机配置为使用1GB内存和2个CPU内核。这对于Spark作业来说是不够的，所以一定要在你的Docker <a href="https://docs.docker.com/docker-for-mac/#advanced">客户端</a>(对于HyperKit)或者直接在VirtualBox中增加内存。然后，当您启动Minikube时，将内存和CPU选项传递给它:</p>
<div class="codehilite"><pre><span/><code>$ minikube start --vm-driver<span class="o">=</span>hyperkit --memory <span class="m">8192</span> --cpus <span class="m">4</span>

or

$ minikube start --memory <span class="m">8192</span> --cpus <span class="m">4</span>
</code></pre></div>

<h2 id="docker">码头工人</h2>
<p>接下来，让我们为Spark <a href="https://spark.apache.org/releases/spark-release-3-2-0.html"> 3.2.0 </a>构建一个定制的Docker映像，它是为Spark <a href="https://spark.apache.org/docs/3.2.0/spark-standalone.html">单机模式</a>设计的。</p>
<p><em> Dockerfile </em>:</p>
<div class="codehilite"><pre><span/><code><span class="c"># base image</span>
<span class="k">FROM</span><span class="w"> </span><span class="s">openjdk:11</span>

<span class="c"># define spark and hadoop versions</span>
<span class="k">ENV</span><span class="w"> </span><span class="nv">SPARK_VERSION</span><span class="o">=</span><span class="m">3</span>.2.0
<span class="k">ENV</span><span class="w"> </span><span class="nv">HADOOP_VERSION</span><span class="o">=</span><span class="m">3</span>.3.1

<span class="c"># download and install hadoop</span>
<span class="k">RUN</span><span class="w"> </span>mkdir -p /opt <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">cd</span> /opt <span class="o">&amp;&amp;</span> <span class="se">\</span>
    curl http://archive.apache.org/dist/hadoop/common/hadoop-<span class="si">${</span><span class="nv">HADOOP_VERSION</span><span class="si">}</span>/hadoop-<span class="si">${</span><span class="nv">HADOOP_VERSION</span><span class="si">}</span>.tar.gz <span class="p">|</span> <span class="se">\</span>
        tar -zx hadoop-<span class="si">${</span><span class="nv">HADOOP_VERSION</span><span class="si">}</span>/lib/native <span class="o">&amp;&amp;</span> <span class="se">\</span>
    ln -s hadoop-<span class="si">${</span><span class="nv">HADOOP_VERSION</span><span class="si">}</span> hadoop <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">echo</span> Hadoop <span class="si">${</span><span class="nv">HADOOP_VERSION</span><span class="si">}</span> native libraries installed <span class="k">in</span> /opt/hadoop/lib/native

<span class="c"># download and install spark</span>
<span class="k">RUN</span><span class="w"> </span>mkdir -p /opt <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">cd</span> /opt <span class="o">&amp;&amp;</span> <span class="se">\</span>
    curl http://archive.apache.org/dist/spark/spark-<span class="si">${</span><span class="nv">SPARK_VERSION</span><span class="si">}</span>/spark-<span class="si">${</span><span class="nv">SPARK_VERSION</span><span class="si">}</span>-bin-hadoop2.7.tgz <span class="p">|</span> <span class="se">\</span>
        tar -zx <span class="o">&amp;&amp;</span> <span class="se">\</span>
    ln -s spark-<span class="si">${</span><span class="nv">SPARK_VERSION</span><span class="si">}</span>-bin-hadoop2.7 spark <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">echo</span> Spark <span class="si">${</span><span class="nv">SPARK_VERSION</span><span class="si">}</span> installed <span class="k">in</span> /opt

<span class="c"># add scripts and update spark default config</span>
<span class="k">ADD</span><span class="w"> </span>common.sh spark-master spark-worker /
<span class="k">ADD</span><span class="w"> </span>spark-defaults.conf /opt/spark/conf/spark-defaults.conf
<span class="k">ENV</span><span class="w"> </span>PATH <span class="nv">$PATH</span>:/opt/spark/bin
</code></pre></div>

<p>你可以在GitHub的<a href="https://github.com/testdrivenio/spark-kubernetes"> spark-kubernetes </a> repo中找到上面的<em> Dockerfile </em>以及Spark配置文件和脚本。</p>
<p>建立形象:</p>
<div class="codehilite"><pre><span/><code>$ <span class="nb">eval</span> <span class="k">$(</span>minikube docker-env<span class="k">)</span>
$ docker build -f docker/Dockerfile -t spark-hadoop:3.2.0 ./docker
</code></pre></div>

<blockquote>
<p>如果你不想花时间在本地构建映像，请随意使用我从<a href="https://hub.docker.com/">Docker Hub</a>:<a href="https://hub.docker.com/r/mjhea0/spark-hadoop/tags">mj hea 0/Spark-Hadoop:3 . 2 . 0</a>中预先构建的Spark映像。</p>
</blockquote>
<p>查看:</p>
<div class="codehilite"><pre><span/><code>$ docker image ls spark-hadoop

REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
spark-hadoop        <span class="m">3</span>.2.0               8f3ccdadd795        <span class="m">11</span> minutes ago      <span class="m">1</span>.12GB
</code></pre></div>

<h2 id="spark-master">火花大师</h2>
<p><em>spark-master-deployment . YAML</em>:</p>
<div class="codehilite"><pre><span/><code><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Deployment</span><span class="w"/>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">apps/v1</span><span class="w"/>
<span class="nt">metadata</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-master</span><span class="w"/>
<span class="nt">spec</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"/>
<span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w"/>
<span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w"/>
<span class="w">      </span><span class="nt">component</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-master</span><span class="w"/>
<span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w"/>
<span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w"/>
<span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w"/>
<span class="w">        </span><span class="nt">component</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-master</span><span class="w"/>
<span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w"/>
<span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w"/>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-master</span><span class="w"/>
<span class="w">          </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-hadoop:3.2.0</span><span class="w"/>
<span class="w">          </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">"/spark-master"</span><span class="p p-Indicator">]</span><span class="w"/>
<span class="w">          </span><span class="nt">ports</span><span class="p">:</span><span class="w"/>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">7077</span><span class="w"/>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8080</span><span class="w"/>
<span class="w">          </span><span class="nt">resources</span><span class="p">:</span><span class="w"/>
<span class="w">            </span><span class="nt">requests</span><span class="p">:</span><span class="w"/>
<span class="w">              </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100m</span><span class="w"/>
</code></pre></div>

<p><em>spark-master-service . YAML</em>:</p>
<div class="codehilite"><pre><span/><code><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Service</span><span class="w"/>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span><span class="w"/>
<span class="nt">metadata</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-master</span><span class="w"/>
<span class="nt">spec</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="nt">ports</span><span class="p">:</span><span class="w"/>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">webui</span><span class="w"/>
<span class="w">      </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8080</span><span class="w"/>
<span class="w">      </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8080</span><span class="w"/>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark</span><span class="w"/>
<span class="w">      </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">7077</span><span class="w"/>
<span class="w">      </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">7077</span><span class="w"/>
<span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w"/>
<span class="w">    </span><span class="nt">component</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-master</span><span class="w"/>
</code></pre></div>

<p>创建Spark主部署并启动服务:</p>
<div class="codehilite"><pre><span/><code>$ kubectl create -f ./kubernetes/spark-master-deployment.yaml
$ kubectl create -f ./kubernetes/spark-master-service.yaml
</code></pre></div>

<p>验证:</p>
<div class="codehilite"><pre><span/><code>$ kubectl get deployments

NAME           READY   UP-TO-DATE   AVAILABLE   AGE
spark-master   <span class="m">1</span>/1     <span class="m">1</span>            <span class="m">1</span>           2m55s


$ kubectl get pods

NAME                          READY   STATUS    RESTARTS   AGE
spark-master-dbc47bc9-tlgfs   <span class="m">1</span>/1     Running   <span class="m">0</span>          3m8s
</code></pre></div>

<h2 id="spark-workers">星火工人</h2>
<p>spark-worker-deployment . YAML:</p>
<div class="codehilite"><pre><span/><code><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Deployment</span><span class="w"/>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">apps/v1</span><span class="w"/>
<span class="nt">metadata</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-worker</span><span class="w"/>
<span class="nt">spec</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span><span class="w"/>
<span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w"/>
<span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w"/>
<span class="w">      </span><span class="nt">component</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-worker</span><span class="w"/>
<span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w"/>
<span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w"/>
<span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w"/>
<span class="w">        </span><span class="nt">component</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-worker</span><span class="w"/>
<span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w"/>
<span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w"/>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-worker</span><span class="w"/>
<span class="w">          </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-hadoop:3.2.0</span><span class="w"/>
<span class="w">          </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">"/spark-worker"</span><span class="p p-Indicator">]</span><span class="w"/>
<span class="w">          </span><span class="nt">ports</span><span class="p">:</span><span class="w"/>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8081</span><span class="w"/>
<span class="w">          </span><span class="nt">resources</span><span class="p">:</span><span class="w"/>
<span class="w">            </span><span class="nt">requests</span><span class="p">:</span><span class="w"/>
<span class="w">              </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100m</span><span class="w"/>
</code></pre></div>

<p>创建Spark worker部署:</p>
<div class="codehilite"><pre><span/><code>$ kubectl create -f ./kubernetes/spark-worker-deployment.yaml
</code></pre></div>

<p>验证:</p>
<div class="codehilite"><pre><span/><code>$ kubectl get deployments

NAME           READY   UP-TO-DATE   AVAILABLE   AGE
spark-master   <span class="m">1</span>/1     <span class="m">1</span>            <span class="m">1</span>           6m35s
spark-worker   <span class="m">2</span>/2     <span class="m">2</span>            <span class="m">2</span>           7s


$ kubectl get pods

NAME                            READY   STATUS    RESTARTS   AGE
spark-master-dbc47bc9-tlgfs     <span class="m">1</span>/1     Running   <span class="m">0</span>          6m53s
spark-worker-795dc47587-fjkjt   <span class="m">1</span>/1     Running   <span class="m">0</span>          25s
spark-worker-795dc47587-g9n64   <span class="m">1</span>/1     Running   <span class="m">0</span>          25s
</code></pre></div>

<h2 id="ingress">进入</h2>
<p>你有没有注意到我们在8080端口暴露了Spark web UI？为了在集群外部访问它，让我们配置一个<a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">入口</a>对象。</p>
<p><em> minikube-ingress.yaml </em>:</p>
<div class="codehilite"><pre><span/><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">networking.k8s.io/v1</span><span class="w"/>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Ingress</span><span class="w"/>
<span class="nt">metadata</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">minikube-ingress</span><span class="w"/>
<span class="w">  </span><span class="nt">annotations</span><span class="p">:</span><span class="w"/>
<span class="nt">spec</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="nt">rules</span><span class="p">:</span><span class="w"/>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">host</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-kubernetes</span><span class="w"/>
<span class="w">    </span><span class="nt">http</span><span class="p">:</span><span class="w"/>
<span class="w">      </span><span class="nt">paths</span><span class="p">:</span><span class="w"/>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">pathType</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Prefix</span><span class="w"/>
<span class="w">          </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/</span><span class="w"/>
<span class="w">          </span><span class="nt">backend</span><span class="p">:</span><span class="w"/>
<span class="w">            </span><span class="nt">service</span><span class="p">:</span><span class="w"/>
<span class="w">              </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-master</span><span class="w"/>
<span class="w">              </span><span class="nt">port</span><span class="p">:</span><span class="w"/>
<span class="w">                </span><span class="nt">number</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8080</span><span class="w"/>
</code></pre></div>

<p>启用入口<a href="https://github.com/kubernetes/minikube/tree/master/deploy/addons/ingress">插件</a>:</p>
<div class="codehilite"><pre><span/><code>$ minikube addons <span class="nb">enable</span> ingress
</code></pre></div>

<p>创建入口对象:</p>
<div class="codehilite"><pre><span/><code>$ kubectl apply -f ./kubernetes/minikube-ingress.yaml
</code></pre></div>

<p>接下来，您需要更新您的<em> /etc/hosts </em>文件，以便将请求从我们定义的主机<code>spark-kubernetes</code>路由到Minikube实例。</p>
<p>将条目添加到/etc/hosts:</p>
<div class="codehilite"><pre><span/><code>$ <span class="nb">echo</span> <span class="s2">"</span><span class="k">$(</span>minikube ip<span class="k">)</span><span class="s2"> spark-kubernetes"</span> <span class="p">|</span> sudo tee -a /etc/hosts
</code></pre></div>

<p>在浏览器中进行测试，网址为<a href="http://spark-kubernetes/"> http://spark-kubernetes/ </a>:</p>
<p><img data-src="/static/images/blog/spark-kubernetes/spark-web-ui.png" loading="lazy" class="lazyload" alt="spark web ui" src="../Images/38a1107458a814a328b4b86915748823.png" data-original-src="https://testdriven.io/static/images/blog/spark-kubernetes/spark-web-ui.png"/></p>
<h2 id="test">试验</h2>
<p>要进行测试，从主容器运行PySpark shell:</p>
<div class="codehilite"><pre><span/><code>$ kubectl get pods -o wide

NAME                            READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
spark-master-dbc47bc9-t6v84     <span class="m">1</span>/1     Running   <span class="m">0</span>          7m35s   <span class="m">172</span>.17.0.6   minikube   &lt;none&gt;           &lt;none&gt;
spark-worker-795dc47587-5ch8f   <span class="m">1</span>/1     Running   <span class="m">0</span>          7m24s   <span class="m">172</span>.17.0.9   minikube   &lt;none&gt;           &lt;none&gt;
spark-worker-795dc47587-fvcf6   <span class="m">1</span>/1     Running   <span class="m">0</span>          7m24s   <span class="m">172</span>.17.0.7   minikube   &lt;none&gt;           &lt;none&gt;

$ kubectl <span class="nb">exec</span> spark-master-dbc47bc9-t6v84 -it -- <span class="se">\</span>
    pyspark --conf spark.driver.bindAddress<span class="o">=</span><span class="m">172</span>.17.0.6 --conf spark.driver.host<span class="o">=</span><span class="m">172</span>.17.0.6
</code></pre></div>

<p>然后在PySpark提示符出现后运行以下代码:</p>
<div class="codehilite"><pre><span/><code><span class="n">words</span> <span class="o">=</span> <span class="s1">'the quick brown fox jumps over the</span><span class="se">\</span>
<span class="s1">        lazy dog the quick brown fox jumps over the lazy dog'</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">seq</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="nb">dict</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</code></pre></div>

<p>您应该看到:</p>
<div class="codehilite"><pre><span/><code><span class="o">{</span><span class="s1">'brown'</span>: <span class="m">2</span>, <span class="s1">'lazy'</span>: <span class="m">2</span>, <span class="s1">'over'</span>: <span class="m">2</span>, <span class="s1">'fox'</span>: <span class="m">2</span>, <span class="s1">'dog'</span>: <span class="m">2</span>, <span class="s1">'quick'</span>: <span class="m">2</span>, <span class="s1">'the'</span>: <span class="m">4</span>, <span class="s1">'jumps'</span>: <span class="m">2</span><span class="o">}</span>
</code></pre></div>

<p>就是这样！</p>
<hr/>

<p>你可以在GitHub的<a href="https://github.com/testdrivenio/spark-kubernetes"> spark-kubernetes </a> repo中找到这些脚本。干杯！</p>
  </div>

  </div>    
</body>
</html>